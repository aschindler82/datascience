{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Malaria Detection: Train", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Found 19290 images belonging to 2 classes.\nFound 5512 images belonging to 2 classes.\n"
                }
            ], 
            "source": "# load and scale images using keras\n# scale pixel values to a range of 0 - 1\n# get image processors for training, testing and evaluation\n# classes will be extracted automatically from subdirectories\n\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrainDir = './trainData'\ntestDir  = './testData'\n\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        trainDir,\n        target_size=(64, 64),\n        batch_size=32,\n        class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        testDir,\n        target_size=(64, 64),\n        batch_size=32,\n        class_mode='binary')\n"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# define network architecture\n# we will use a similar architecture as th VGG net\n\nimport numpy as np\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Activation\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import SGD\n\nimport tensorflow as tf\n\nmodel = Sequential()\n# input: 64x64 images with 3 channels -> (64, 64, 3) tensors.\n# this applies 32 convolution filters of size 3x3 each.\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\n#model.add(Dense(2))\n#model.add(Activation(tf.nn.softmax))\n#model.add(Dense(2, activation='softmax'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\n# add accurary as metrics\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Epoch 1/25\n602/602 [==============================] - 1197s - loss: 0.6574 - acc: 0.6129 - val_loss: 0.4816 - val_acc: 0.8098\nEpoch 2/25\n602/602 [==============================] - 1141s - loss: 0.3283 - acc: 0.8898 - val_loss: 0.1853 - val_acc: 0.9420\nEpoch 3/25\n602/602 [==============================] - 1025s - loss: 0.2049 - acc: 0.9336 - val_loss: 0.1533 - val_acc: 0.9593\nEpoch 4/25\n602/602 [==============================] - 1028s - loss: 0.1815 - acc: 0.9464 - val_loss: 0.1488 - val_acc: 0.9589\nEpoch 5/25\n602/602 [==============================] - 1064s - loss: 0.1702 - acc: 0.9479 - val_loss: 0.1430 - val_acc: 0.9573\nEpoch 6/25\n602/602 [==============================] - 1057s - loss: 0.1617 - acc: 0.9509 - val_loss: 0.1353 - val_acc: 0.9593\nEpoch 7/25\n602/602 [==============================] - 1132s - loss: 0.1562 - acc: 0.9509 - val_loss: 0.1340 - val_acc: 0.9618\nEpoch 8/25\n602/602 [==============================] - 1162s - loss: 0.1526 - acc: 0.9529 - val_loss: 0.1335 - val_acc: 0.9598\nEpoch 9/25\n602/602 [==============================] - 1170s - loss: 0.1516 - acc: 0.9525 - val_loss: 0.1280 - val_acc: 0.9598\nEpoch 10/25\n602/602 [==============================] - 1086s - loss: 0.1461 - acc: 0.9530 - val_loss: 0.1292 - val_acc: 0.9602\nEpoch 11/25\n602/602 [==============================] - 1060s - loss: 0.1438 - acc: 0.9550 - val_loss: 0.1226 - val_acc: 0.9626\nEpoch 12/25\n602/602 [==============================] - 1089s - loss: 0.1396 - acc: 0.9549 - val_loss: 0.1216 - val_acc: 0.9602\nEpoch 13/25\n602/602 [==============================] - 1162s - loss: 0.1419 - acc: 0.9548 - val_loss: 0.1223 - val_acc: 0.9617\nEpoch 14/25\n602/602 [==============================] - 1138s - loss: 0.1371 - acc: 0.9561 - val_loss: 0.1230 - val_acc: 0.9629\nEpoch 15/25\n602/602 [==============================] - 1181s - loss: 0.1386 - acc: 0.9562 - val_loss: 0.1194 - val_acc: 0.9609\nEpoch 16/25\n602/602 [==============================] - 1171s - loss: 0.1384 - acc: 0.9564 - val_loss: 0.1225 - val_acc: 0.9615\nEpoch 17/25\n602/602 [==============================] - 1118s - loss: 0.1353 - acc: 0.9556 - val_loss: 0.1209 - val_acc: 0.9626\nEpoch 18/25\n602/602 [==============================] - 1116s - loss: 0.1372 - acc: 0.9556 - val_loss: 0.1301 - val_acc: 0.9591\nEpoch 19/25\n602/602 [==============================] - 1040s - loss: 0.1348 - acc: 0.9563 - val_loss: 0.1156 - val_acc: 0.9620\nEpoch 20/25\n602/602 [==============================] - 1055s - loss: 0.1341 - acc: 0.9566 - val_loss: 0.1145 - val_acc: 0.9620\nEpoch 21/25\n602/602 [==============================] - 1131s - loss: 0.1313 - acc: 0.9567 - val_loss: 0.1223 - val_acc: 0.9637\nEpoch 22/25\n602/602 [==============================] - 1120s - loss: 0.1293 - acc: 0.9591 - val_loss: 0.1179 - val_acc: 0.9618\nEpoch 23/25\n602/602 [==============================] - 1124s - loss: 0.1294 - acc: 0.9563 - val_loss: 0.1196 - val_acc: 0.9591\nEpoch 24/25\n602/602 [==============================] - 1543s - loss: 0.1288 - acc: 0.9566 - val_loss: 0.1167 - val_acc: 0.9618\nEpoch 25/25\n602/602 [==============================] - 1059s - loss: 0.1318 - acc: 0.9563 - val_loss: 0.1139 - val_acc: 0.9615\n"
                }
            ], 
            "source": "# best run over night -> takes some time!\n#\n# during development, it turned out that\n# the loss converges to a minimum after 25 epochs\nepochs = 25\n\n# train the net\nhistory = model.fit_generator(\n            train_generator,\n            steps_per_epoch = train_generator.samples / train_generator.batch_size,\n            epochs = epochs,\n            validation_data = validation_generator,\n            validation_steps = validation_generator.samples / validation_generator.batch_size\n)"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import pickle\n\n# save model to disc\nmodel.save('malaria_model.h5')  # creates a HDF5 file\n\n# save training history\nwith open('malaria_history.pickle', 'wb') as f:\n    pickle.dump([history.history], f)"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.14", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}